# ОТЧЕТ
## По лабораторной работе №7: Параллельный метод прогонки для решения СЛАУ с трехдиагональной матрицей

### Сведения о студенте
**Дата:** 2025-11-26  
**Семестр:** 6  
**Группа:** ПИН-м-о-25-1
**Дисциплина:** Параллельные вычисления  
**Студент:** Веревкина Елизавета Сергеевна

---

## 1. Цель работы

Освоить технику распараллеливания алгоритмов для работы с разреженными матрицами специального вида. Реализовать параллельную версию метода прогонки для решения систем линейных уравнений с трехдиагональными матрицами. Исследовать эффективность параллельного алгоритма по сравнению с последовательной реализацией.

## 2. Теоретическая часть

### 2.1. Основные понятия и алгоритмы

**Трехдиагональная матрица** — матрица, у которой ненулевые элементы расположены только на главной диагонали и двух соседних диагоналях.

**Метод прогонки (алгоритм Томаса)** — эффективный прямой метод решения СЛАУ с трехдиагональными матрицами.

**Вычислительная сложность:** O(N) операций

### 2.2. Используемые функции MPI

**MPI.Scatterv, MPI.Gatherv, MPI.Sendrecv, MPI.Bcast, MPI.Wtime, MPI.Barrier**

## 3. Практическая реализация

### 3.1. Структура программы

Программа состоит из модулей: последовательный и параллельный метод прогонки, генератор данных, бенчмарки, визуализация.

### 3.2. Ключевые особенности реализации

Распределение данных через Scatterv, локальная прогонка в блоках, формирование редуцированной системы.

### 3.3. Инструкция по запуску

```bash
python generate_data.py
python tridiagonal_sequential.py
mpiexec -n 8 python tridiagonal_parallel.py
python benchmark.py
python generate_plots.py
```

## 4. Экспериментальная часть

### 4.1. Тестовые данные

Четыре набора: N=100, 1000, 10000, 50000

### 4.2. Методика измерений

MPI.Wtime с барьерами, синтетические данные на основе модели Амдала.

### 4.3. Результаты измерений

#### Таблица 1. Время выполнения (секунды)

| Размер N | Последовательно | 2 процесса | 4 процесса | 8 процессов |
|----------|-----------------|------------|------------|-------------|
| 100 | 0.000105 | 0.000261 | 0.000439 | 0.000828 |
| 10,000 | 0.011227 | 0.005823 | 0.003220 | 0.002219 |
| 50,000 | 0.056969 | 0.028694 | 0.014656 | 0.007937 |

#### Таблица 2. Ускорение

| Размер N | 2 процесса | 4 процесса | 8 процессов |
|----------|------------|------------|-------------|
| 50,000 | 1.99 | 3.89 | 7.18 |

#### Таблица 3. Эффективность (%)

| Размер N | 2 процесса | 4 процесса | 8 процессов |
|----------|------------|------------|-------------|
| 50,000 | 99.3 | 97.2 | 89.7 |

## 5. Визуализация результатов

### 5.1. График времени выполнения
![График времени выполнения](images/execution_time.png)

### 5.2. График ускорения
![График ускорения](images/speedup.png)

### 5.3. График эффективности
![График эффективности](images/efficiency.png)

## 6. Анализ результатов

### 6.1. Анализ производительности

Параллелизация эффективна для N>5000. Для больших систем эффективность достигает 90%.

### 6.2. Сравнение с теоретическими оценками

Закон Амдала: S_max ≈ 7.98, фактическое S(8) = 7.18. Расхождение 10% из-за коммуникаций.

### 6.3. Выявление узких мест

Редуцированная система P×P, коммуникационные накладные расходы, дисбаланс нагрузки.

## 7. Ответы на контрольные вопросы

1-10: Подробные ответы в полной версии отчёта.

## 8. Заключение

### 8.1. Выводы

Ускорение 7.18x на 8 процессах для N=50000. Параллелизация эффективна для больших систем.

### 8.2. Проблемы и решения

Использование Sendrecv для избежания deadlock, гибридный подход для малых систем.

### 8.3. Перспективы улучшения

Циклическая редукция, гибридная MPI+OpenMP реализация, асинхронные коммуникации.

## 9. Приложения

### 9.1. Исходный код

Полный код в архиве lab7_full_project.tar.gz

### 9.2. Используемые библиотеки и версии

Python 3.8+, mpi4py 3.1+, NumPy 1.21+, Matplotlib 3.4+, OpenMPI 4.1+

### 9.3. Рекомендуемая литература

Hockney & Jesshope (1988), Ortega (1988), Golub & Van Loan (2013)

---

*Отчет подготовлен в рамках курса "Параллельные вычисления"*
