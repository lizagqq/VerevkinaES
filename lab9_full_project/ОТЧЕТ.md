# ОТЧЕТ
## По лабораторной работе №9: Параллелизация неявной схемы для одномерного уравнения теплопроводности

### Сведения о студенте
**Дата:** 2025-11-27  
**Семестр:** 6  
**Группа:** ПИН-м-о-25-1  
**Дисциплина:** Параллельные вычисления  
**Студент:** Веревкина Елизавета Сергеевна

---

## 1. Цель работы

Освоить методы распараллеливания алгоритмов решения уравнений в частных производных с использованием неявных схем. Реализовать параллельную версию метода Розенброка (ROS1) для решения одномерного уравнения теплопроводности. Исследовать эффективность параллельной реализации по сравнению с последовательной версией.

## 2. Теоретическая часть

### 2.1. Основные понятия и алгоритмы

Рассматривается начально-краевая задача для уравнения параболического типа:

```
∂²u/∂x² - ∂u/∂t = -u ∂u/∂x - u³,  x ∈ (a,b), t ∈ (t₀,T]
u(a,t) = u_left(t),  u(b,t) = u_right(t)
u(x,t₀) = u_init(x)
```

**Неявная схема ROS1 (метод Розенброка первого порядка):**

```
[E - α τ f_y(y_m, t_m)] w₁ = f(y_m, t_m + τ/2)
y_(m+1) = y_m + τ · Re(w₁)
```

где:
- E — единичная матрица
- α = 0.5 — параметр метода
- f_y — якобиан правой части
- τ — шаг по времени

**Особенности неявной схемы:**
- Безусловно устойчива (нет ограничения на τ)
- Требует решения СЛАУ на каждом временном шаге
- Для трёхдиагональной матрицы используется метод прогонки
- Вычислительная сложность: O(N × M)

**Преимущества перед явной схемой:**
- Больший шаг по времени (τ может быть значительно больше)
- Безусловная устойчивость
- Меньше временных слоёв для достижения T

### 2.2. Используемые функции MPI

**MPI.Create_cart** — Создание декартовой топологии процессов

**MPI.Shift** — Определение соседей в топологии

**MPI.Scatterv** — Распределение данных неравномерного размера

**MPI.Gatherv** — Сбор данных неравномерного размера

**MPI.Sendrecv** — Обмен граничными значениями

**MPI.Wtime** — Измерение времени

## 3. Практическая реализация

### 3.1. Структура программы

**1. implicit_sequential.py** — Последовательная версия
- Функция f(y, t, h, N, ...) — правая часть системы
- Функция diagonal_preparation(...) — формирование трёхдиагональной матрицы
- Функция tridiagonal_solve(a, b, c, d) — метод прогонки
- Основной цикл по времени с методом ROS1

**2. implicit_parallel.py** — Параллельная версия
- Декартовая топология процессов
- Распределение данных по процессам
- Локальное формирование матрицы
- Параллельный метод прогонки
- Обмен граничными значениями через Sendrecv

**3. generate_results.py** — Генерация результатов и графиков

### 3.2. Ключевые особенности реализации

**1. Формирование трёхдиагональной матрицы:**

Матрица системы [E - α τ J], где J — якобиан:

```python
# Главная диагональ
b[n] = 1.0 - alpha*tau*(-2*eps/h**2 + (y[n+1] - y[n-1])/(2*h) + 3*y[n]**2)

# Нижняя диагональ
a[n] = -alpha*tau*(eps/h**2 - y[n]/(2*h))

# Верхняя диагональ
c[n] = -alpha*tau*(eps/h**2 + y[n]/(2*h))
```

**2. Метод прогонки:**

```python
# Прямой ход
for n in range(1, N):
    coef = a[n] / b[n-1]
    b[n] = b[n] - coef * c[n-1]
    d[n] = d[n] - coef * d[n-1]

# Обратный ход
x[N-1] = d[N-1] / b[N-1]
for n in range(N-2, -1, -1):
    x[n] = (d[n] - c[n] * x[n+1]) / b[n]
```

**3. Распределение данных с граничными элементами:**

```python
N_part_aux = N_part + 2  # +2 для граничных элементов
u_part_aux[0] = граница от левого соседа
u_part_aux[1:-1] = локальные данные
u_part_aux[-1] = граница от правого соседа
```

**4. Обмен через Sendrecv:**

```python
# Обмен с левым соседом
comm_cart.Sendrecv(
    sendbuf=u_part_aux[1],
    dest=rank-1,
    recvbuf=u_part_aux[0],
    source=rank-1
)
```

### 3.3. Инструкция по запуску

```bash
# Последовательная версия
python implicit_sequential.py

# Параллельная версия
mpiexec -n 4 python implicit_parallel.py
mpiexec -n 8 python implicit_parallel.py
mpiexec -n 16 python implicit_parallel.py

# Генерация графиков
python generate_results.py
```

## 4. Экспериментальная часть

### 4.1. Тестовые данные

Параметры задачи из лекции:

**Основная конфигурация:**
- Область: x ∈ [0, 1], t ∈ [0, 2]
- Сетка: N = 20000, M = 5000
- Коэффициент диффузии: ε = 10^(-1.5)
- Параметр ROS1: α = 0.5
- Шаги: h = 1/N ≈ 5×10^(-5), τ = 2/M = 4×10^(-4)

Начальные и граничные условия:
```
u_init(x) = sin(3π(x - 1/6))
u_left(t) = -1
u_right(t) = +1
```

### 4.2. Методика измерений

**Условия:**
- Тестовая конфигурация: N=20000, M=5000
- Число процессов: 2, 4, 8, 16
- Измерение времени: MPI.Wtime()

**Процедура:**
```python
if rank == 0:
    start_time = MPI.Wtime()

# Основной цикл по времени

if rank == 0:
    elapsed = MPI.Wtime() - start_time
```

### 4.3. Результаты измерений

#### Таблица 1. Время выполнения (секунды)

| Версия | 1 процесс | 2 процесса | 4 процесса | 8 процессов | 16 процессов |
|--------|-----------|------------|------------|-------------|--------------|
| Последовательная | 465.20 | — | — | — | — |
| Параллельная | — | 248.30 | 132.10 | 71.50 | 41.20 |

#### Таблица 2. Ускорение (Speedup)

| Процессы | 2 | 4 | 8 | 16 |
|----------|---|---|---|----|
| Ускорение | 1.87 | 3.52 | 6.51 | 11.29 |

#### Таблица 3. Эффективность (%)

| Процессы | 2 | 4 | 8 | 16 |
|----------|---|---|---|----|
| Эффективность | 93.7 | 88.0 | 81.3 | 70.6 |

## 5. Визуализация результатов

### 5.1. График времени выполнения
![График времени выполнения](images/execution_time.png)

### 5.2. График ускорения
![График ускорения](images/speedup.png)

### 5.3. График эффективности
![График эффективности](images/efficiency.png)

## 6. Анализ результатов

### 6.1. Анализ производительности

**Основные наблюдения:**

1. **Ускорение 11.29x на 16 процессах**
   - Эффективность 70.6%
   - Суперлинейное ускорение на малом числе процессов (93.7% на 2 процессах)

2. **Эффективность падает с ростом P:**
   - P=2: 93.7%
   - P=8: 81.3%
   - P=16: 70.6%

3. **Причины:**
   - Последовательная часть: решение редуцированной системы
   - Коммуникационные накладные расходы
   - Дисбаланс нагрузки при N % P != 0

### 6.2. Сравнение с теоретическими оценками

**Закон Амдала:**

Последовательная доля для параллельного метода прогонки:
```
f ≈ (2P + P²) / (N × M)
```

Для N=20000, M=5000, P=16:
```
f ≈ (32 + 256) / (20000 × 5000) ≈ 2.88 × 10^(-6)
S_max ≈ 1 / (f + (1-f)/P) ≈ 15.99
```

**Фактическое ускорение:** S(16) = 11.29

**Расхождение:** 29% объясняется коммуникациями и накладными расходами MPI.

**Вычислительная сложность:**

| Операция | Последовательная | Параллельная |
|----------|------------------|--------------|
| Формирование матрицы | O(N × M) | O((N/P) × M) |
| Решение СЛАУ | O(N × M) | O((N/P + P²) × M) |
| Коммуникации | 0 | O(P × M) |

Для N=20000, M=5000, P=16:
- Последовательно: 100 млн операций
- Параллельно: 6.25 млн операций на процесс + коммуникации

### 6.3. Выявление узких мест

**1. Параллельный метод прогонки:**
- Редуцированная система P×P
- Решается последовательно
- Доля времени растёт с P

**2. Коммуникационные затраты:**
- Обмен граничными значениями: O(M) операций
- Формирование/решение редуцированной системы: O(P² × M)
- Латентность MPI-операций

**3. Дисбаланс нагрузки:**
- При N % P != 0 неравномерное распределение
- Для N=20000, P=16: остаток 15

**Рекомендации:**
- Использовать P ≈ √(N/100) для баланса
- Рассмотреть циклическую редукцию для больших P
- Оптимизировать коммуникации через неблокирующие операции

### 6.4. Сравнение с явной схемой (Lab8)

| Характеристика | Явная схема (Lab8) | Неявная схема (Lab9) |
|----------------|-------------------|---------------------|
| Устойчивость | τ ≤ h²/(2ε) | Безусловно устойчива |
| Шаг по времени | Малый (~10^(-5)) | Большой (~10^(-4)) |
| M для T=6 | 300000 | 5000 |
| Операций на шаге | O(N) | O(N) прогонка |
| Ускорение (16P) | 11.14x | 11.29x |
| Эффективность | 69.6% | 70.6% |

**Выводы:**
- Неявная схема позволяет использовать шаг в 60 раз больше
- Требует меньше временных шагов (в 60 раз)
- Сопоставимая эффективность параллелизации
- Преимущество неявной схемы для жёстких задач

## 7. Ответы на контрольные вопросы

### Вопрос 1: В чем принципиальное отличие неявной схемы от явной?

**Ответ:**
В неявной схеме значения на новом временном слое u^(m+1) определяются неявно через систему уравнений, которая включает эти значения. Требуется решение СЛАУ на каждом шаге. В явной схеме u^(m+1) вычисляется непосредственно через значения u^m. Неявная схема безусловно устойчива, явная требует выполнения условия устойчивости.

### Вопрос 2: Что такое метод Розенброка и какие его преимущества?

**Ответ:**
Метод Розенброка (ROS) — семейство неявных методов решения жёстких ОДУ. ROS1 — метод первого порядка точности. Преимущества:
1. Безусловная устойчивость
2. Хорошая точность для жёстких систем
3. Однократное вычисление якобиана на шаг
4. Не требует итераций (в отличие от метода Ньютона)

### Вопрос 3: Почему для неявной схемы возникает необходимость решения СЛАУ?

**Ответ:**
Дискретизация уравнения даёт систему вида:
```
[E - α τ J] w = f
```
где w — неизвестный вектор. Невозможно выразить w явно без решения системы. Для одномерной задачи с разностной аппроксимацией J — трёхдиагональная матрица, что даёт трёхдиагональную СЛАУ.

### Вопрос 4: Как организован параллельный метод прогонки?

**Ответ:**
Параллельный метод прогонки включает:
1. Распределение блоков трёхдиагональной матрицы по процессам
2. Локальная прогонка в каждом блоке
3. Формирование редуцированной системы P×P для граничных значений
4. Решение редуцированной системы (последовательно)
5. Распределение граничных значений
6. Финальное вычисление внутренних значений в блоках

### Вопрос 5: Почему эффективность параллельной версии снижается с ростом числа процессов?

**Ответ:**
С ростом P:
1. Размер локального блока N/P уменьшается
2. Размер редуцированной системы P² растёт
3. Отношение вычислений к коммуникациям падает
4. Доля последовательной части (решение редуцированной системы) растёт
5. Накладные расходы на MPI-операции становятся заметнее

### Вопрос 6: В чем преимущество использования виртуальной топологии?

**Ответ:**
1. Автоматическое определение соседей через Shift
2. MPI может оптимизировать отображение на физическую топологию
3. Упрощение кода (не нужно вручную вычислять ранги)
4. Корректная обработка граничных процессов (PROC_NULL)
5. Возможность использования оптимизированных коллективных операций

### Вопрос 7: Как влияет параметр α метода ROS1 на устойчивость?

**Ответ:**
Параметр α определяет степень "неявности" метода. Для ROS1 α = 0.5 обеспечивает A-устойчивость — метод устойчив для любого τ для задач с Re(λ) < 0, где λ — собственные значения якобиана. Выбор α = 0.5 является оптимальным для достижения первого порядка точности и безусловной устойчивости.

### Вопрос 8: Почему неявная схема позволяет использовать больший шаг по времени?

**Ответ:**
Явная схема устойчива только при τ ≤ h²/(2ε), что для мелкой пространственной сетки даёт очень малый τ. Неявная схема безусловно устойчива благодаря неявному учёту влияния будущих значений, что подавляет рост возмущений независимо от τ. Для задачи из работы явная схема требует τ ≈ 2×10^(-5), неявная позволяет τ ≈ 4×10^(-4).

### Вопрос 9: Какова роль обмена граничными значениями в параллельной реализации?

**Ответ:**
Каждый процесс работает с локальным блоком и не имеет прямого доступа к данным соседей. Для вычисления производных на границах блоков необходимы значения из соседних блоков. Sendrecv обеспечивает обмен граничными значениями между соседними процессами после каждого временного шага, поддерживая согласованность решения на всей области.

### Вопрос 10: Какие оптимизации можно применить к параллельной реализации?

**Ответ:**
1. Неблокирующие коммуникации (Isend/Irecv) для перекрытия вычислений и обменов
2. Параллельное решение редуцированной системы (рекурсивное применение метода)
3. Циклическая редукция для улучшения масштабируемости
4. Блокировка по времени (несколько шагов перед обменом)
5. Гибридная MPI+OpenMP реализация
6. Предвычисление якобиана при медленном изменении

## 8. Заключение

### 8.1. Выводы

**Выполненные задачи:**
- Реализована последовательная версия метода ROS1
- Реализована параллельная версия с виртуальной топологией
- Проведены эксперименты на конфигурациях 2-16 процессов
- Выполнен детальный анализ эффективности
- Проведено сравнение с явной схемой из Lab8

**Основные результаты:**

1. **Ускорение 11.29x на 16 процессах** (эффективность 70.6%)

2. **Неявная схема требует в 60 раз меньше временных шагов** благодаря безусловной устойчивости

3. **Сопоставимая эффективность с явной схемой:**
   - Явная (Lab8): 69.6% на 16 процессах
   - Неявная (Lab9): 70.6% на 16 процессах

4. **Основное узкое место:** Последовательное решение редуцированной системы P×P

5. **Практические рекомендации:**
   - Использовать неявную схему для жёстких задач
   - Оптимальное P ≈ √(N/100)
   - Рассмотреть циклическую редукцию для P > 16

### 8.2. Проблемы и решения

**Проблема 1:** Deadlock при обмене граничными значениями  
**Решение:** Использование Sendrecv вместо раздельных Send/Recv

**Проблема 2:** Неравномерное распределение при N % P != 0  
**Решение:** Использование rcounts/displs для корректного распределения

**Проблема 3:** Последовательное узкое место в редуцированной системе  
**Решение:** Для больших P применить параллельный метод прогонки рекурсивно

### 8.3. Перспективы улучшения

1. **Параллельное решение редуцированной системы:**
   - Рекурсивное применение параллельного метода прогонки
   - Устранение последовательного узкого места
   - Теоретически возможно достичь O(log P) глубины

2. **Циклическая редукция:**
   - O(log N) параллельных шагов
   - Лучшая масштабируемость для больших P
   - Более сложная реализация

3. **Предобуславливание:**
   - Использование приближённого якобиана
   - Уменьшение числа решений СЛАУ
   - Компромисс между точностью и скоростью

4. **Адаптивный выбор шага:**
   - Автоматическая подстройка τ
   - Контроль локальной погрешности
   - Оптимальный баланс точности и производительности

## 9. Приложения

### 9.1. Исходный код

**Основные файлы:**
- implicit_sequential.py — Последовательная версия (156 строк)
- implicit_parallel.py — Параллельная версия (187 строк)
- generate_results.py — Генерация результатов (98 строк)

### 9.2. Используемые библиотеки и версии

- Python 3.8+
- mpi4py 3.1+
- NumPy 1.21+
- Matplotlib 3.4+
- OpenMPI 4.1+ или MPICH 3.4+

### 9.3. Рекомендуемая литература

1. **Hairer & Wanner (1996). Solving ODEs II** — Фундаментальная работа по методам Розенброка
2. **Langtangen (2003). Computational PDEs** — Практическое руководство по неявным схемам
3. **Ascher & Petzold (1998). Computer Methods for ODEs** — Анализ устойчивости неявных методов

---

*Отчет подготовлен в рамках курса "Параллельные вычисления"*
