# ОТЧЕТ
## По лабораторной работе №10: Параллелизация двумерного уравнения теплопроводности

### Сведения о студенте
**Дата:** 2025-11-29  
**Семестр:** 6  
**Группа:** ПИН-м-о-25-1  
**Дисциплина:** Параллельные вычисления  
**Студент:** Веревкина Елизавета Сергеевна

---

## 1. Цель работы

Освоить методы распараллеливания алгоритмов решения многомерных уравнений в частных производных. Реализовать параллельные версии решения двумерного уравнения теплопроводности с использованием одномерной и двумерной декомпозиции расчетной области. Исследовать эффективность различных подходов к распараллеливанию.

## 2. Теоретическая часть

### 2.1. Основные понятия и алгоритмы

Рассматривается начально-краевая задача для двумерного уравнения параболического типа:

```
ε(∂²u/∂x² + ∂²u/∂y²) - ∂u/∂t = -u(∂u/∂x + ∂u/∂y) - u³
(x,y) ∈ (a,b) × (c,d), t ∈ (t₀,T]

u(a,y,t) = u_left(y,t),  u(b,y,t) = u_right(y,t)
u(x,c,t) = u_bottom(x,t), u(x,d,t) = u_top(x,t)
u(x,y,t₀) = u_init(x,y)
```

**Явная разностная схема:**

```
u_(i,j)^(m+1) = u_(i,j)^m + τ[ε(∂²u/∂x² + ∂²u/∂y²) + 
                             u_(i,j)^m(∂u/∂x + ∂u/∂y) + (u_(i,j)^m)³]
```

где вторые производные аппроксимируются центральными разностями:
```
∂²u/∂x² ≈ (u_(i+1,j) - 2u_(i,j) + u_(i-1,j)) / h_x²
∂²u/∂y² ≈ (u_(i,j+1) - 2u_(i,j) + u_(i,j-1)) / h_y²
```

**Вычислительная сложность:** O(N_x × N_y × M) операций

**Особенности двумерной задачи:**
- Значительно больший объём данных: O(N_x × N_y) вместо O(N)
- Коммуникации по двум направлениям
- Возможность использования различных стратегий декомпозиции

### 2.2. Методы декомпозиции области

**Одномерная декомпозиция (1D):**
- Разбиение только по одному измерению (например, по x)
- Каждый процесс получает вертикальную полосу области
- Обмен данными только между соседями по x
- Число процессов: произвольное P

**Двумерная декомпозиция (2D):**
- Разбиение по обоим измерениям (по x и y)
- Каждый процесс получает прямоугольный блок
- Обмен данными с 4 соседями (сверху, снизу, слева, справа)
- Число процессов: P = P_x × P_y (обычно P_x = P_y = √P)

### 2.3. Используемые функции MPI

**MPI.Create_cart** — Создание декартовой топологии (линейная или сетка)

**MPI.Get_coords** — Получение координат процесса в топологии

**MPI.Sendrecv** — Обмен граничными значениями

**MPI.Wtime** — Измерение времени

## 3. Практическая реализация

### 3.1. Структура программы

**1. heat2d_sequential.py** — Последовательная версия
- Явная схема для двумерного уравнения
- Три вложенных цикла: по времени, по x, по y
- Вычисление производных центральными разностями

**2. heat2d_1d_decomp.py** — 1D декомпозиция
- Линейная топология процессов
- Разбиение по x, полная область по y
- Обмен вертикальных срезов между соседями

**3. heat2d_2d_decomp.py** — 2D декомпозиция
- Сеточная топология P_x × P_y
- Разбиение по обоим измерениям
- Обмен с четырьмя соседями

**4. generate_results.py** — Генерация результатов и графиков

### 3.2. Ключевые особенности реализации

**1. Определение размеров локальных блоков:**

Для 1D декомпозиции:
```python
N_x_part = (N_x + 1) // size + (1 if rank < (N_x+1) % size else 0)
N_x_part_aux = N_x_part + 2  # С граничными элементами
```

Для 2D декомпозиции:
```python
N_x_part = (N_x + 1) // num_col + ...
N_y_part = (N_y + 1) // num_row + ...
```

**2. Граничные элементы:**

1D: Каждый внутренний процесс имеет +2 элемента по x
2D: Каждый внутренний процесс имеет +2 элемента по x и по y

**3. Обмен данными в 1D:**

```python
# Обмен с левым соседом
comm_cart.Sendrecv(
    sendbuf=u_part_aux[m+1, 1, :],     # Отправка второго слоя
    dest=rank-1,
    recvbuf=u_part_aux[m+1, 0, :],     # Приём в граничный слой
    source=rank-1
)
```

**4. Обмен данными в 2D:**

Обмен по x (горизонтальные срезы):
```python
comm_cart.Sendrecv(
    sendbuf=u_part_aux[m+1, 1, :],
    dest=my_row*num_col + (my_col-1),
    recvbuf=u_part_aux[m+1, 0, :],
    source=my_row*num_col + (my_col-1)
)
```

Обмен по y (вертикальные срезы, требуется копирование):
```python
temp_send = u_part_aux[m+1, :, 1].copy()
comm_cart.Sendrecv(sendbuf=temp_send, ...)
u_part_aux[m+1, :, 0] = temp_recv
```

### 3.3. Инструкция по запуску

```bash
# Последовательная версия
python heat2d_sequential.py

# 1D декомпозиция
mpiexec -n 4 python heat2d_1d_decomp.py
mpiexec -n 8 python heat2d_1d_decomp.py
mpiexec -n 16 python heat2d_1d_decomp.py

# 2D декомпозиция (P должно быть полным квадратом)
mpiexec -n 4 python heat2d_2d_decomp.py
mpiexec -n 9 python heat2d_2d_decomp.py
mpiexec -n 16 python heat2d_2d_decomp.py

# Генерация графиков
python generate_results.py
```

## 4. Экспериментальная часть

### 4.1. Тестовые данные

Параметры задачи из лекции:

**Основная конфигурация:**
- Область: x ∈ [-2, 2], y ∈ [-2, 2]
- Время: t ∈ [0, 4]
- Сетка: N_x = N_y = 200, M = 4000
- Коэффициент диффузии: ε = 10^(-1.5)
- Шаги: h_x = h_y = 0.02, τ = 0.001

Начальное и граничные условия:
```
u_init(x,y) = 0.5 tanh(1/ε ((x-0.5)² + (y-0.5)² - 0.35²)) - 0.17
u_left = u_right = u_top = u_bottom = 0.33
```

### 4.2. Методика измерений

**Условия:**
- Тестовая конфигурация: N_x = N_y = 200, M = 4000
- Число процессов:
  - 1D: 2, 4, 8, 16
  - 2D: 4, 9, 16 (2×2, 3×3, 4×4)
- Измерение времени: MPI.Wtime()

**Процедура:**
```python
if rank == 0:
    start_time = MPI.Wtime()

# Основной цикл по времени

if rank == 0:
    elapsed = MPI.Wtime() - start_time
```

### 4.3. Результаты измерений

#### Таблица 1. Время выполнения (секунды)

| Версия | 1 | 2 | 4 | 8 | 9 | 16 |
|--------|---|---|---|---|---|----|
| Последовательная | 1082.40 | — | — | — | — | — |
| 1D декомпозиция | — | 562.30 | 298.40 | 162.50 | — | 94.20 |
| 2D декомпозиция | — | — | 285.10 | — | 142.60 | 81.30 |

#### Таблица 2. Ускорение (Speedup)

| Процессы | 1D декомпозиция | 2D декомпозиция |
|----------|-----------------|-----------------|
| 2 | 1.92 | — |
| 4 | 3.63 | 3.80 |
| 8 | 6.66 | — |
| 9 | — | 7.59 |
| 16 | 11.49 | 13.31 |

#### Таблица 3. Эффективность (%)

| Процессы | 1D декомпозиция | 2D декомпозиция |
|----------|-----------------|-----------------|
| 2 | 96.2 | — |
| 4 | 90.7 | 94.9 |
| 8 | 83.3 | — |
| 9 | — | 84.3 |
| 16 | 71.8 | 83.2 |

## 5. Визуализация результатов

### 5.1. График времени выполнения
![График времени выполнения](images/execution_time.png)

### 5.2. График ускорения
![График ускорения](images/speedup.png)

### 5.3. График эффективности
![График эффективности](images/efficiency.png)

## 6. Анализ результатов

### 6.1. Анализ производительности

**Сравнение подходов:**

1. **2D декомпозиция превосходит 1D:**
   - На 16 процессах: 13.31x vs 11.49x (превосходство 16%)
   - Эффективность: 83.2% vs 71.8%

2. **Причины преимущества 2D:**
   - Меньший объём коммуникаций на процесс
   - Лучшее отношение периметра к площади блока
   - Меньшая зависимость от числа процессов

3. **Масштабируемость:**
   - 1D: эффективность падает с 96.2% (P=2) до 71.8% (P=16)
   - 2D: эффективность остаётся высокой 83.2% (P=16)

### 6.2. Анализ коммуникационных затрат

**Объём передаваемых данных на один временной шаг:**

1D декомпозиция (разбиение по x):
```
V_comm_1D = 2 × (N_y + 1) × P
```
Каждый процесс обменивается с 2 соседями по вертикальному срезу размером (N_y + 1).

2D декомпозиция (разбиение по x и y):
```
V_comm_2D = 2 × [(N_y+1)/√P + (N_x+1)/√P] × P
         = 2√P × [(N_y+1) + (N_x+1)]
```
Каждый процесс обменивается с 4 соседями по граничным линиям.

**Для N_x = N_y = 200:**

1D (P=16):
```
V_comm_1D = 2 × 201 × 16 = 6432 элемента
```

2D (P=16, 4×4):
```
V_comm_2D = 2 × 4 × (201 + 201) = 3216 элементов
```

**Отношение:** V_comm_1D / V_comm_2D = 2

2D декомпозиция передаёт в 2 раза меньше данных!

**Отношение вычислений к коммуникациям:**

1D:
```
Work / Comm = (N_x × N_y / P) / (N_y) = N_x / P
```

2D:
```
Work / Comm = (N_x × N_y / P) / (N_x/√P + N_y/√P) 
            = (N_x × N_y) / (P × (N_x + N_y) / √P)
            = √P × (N_x × N_y) / (N_x + N_y)
```

Для N_x = N_y = N:
- 1D: N / P
- 2D: √P × N / 2

При P=16, N=200:
- 1D: 200/16 = 12.5
- 2D: 4 × 200/2 = 400

Отношение W/C для 2D в 32 раза лучше!

### 6.3. Выявление узких мест

**1. Одномерная декомпозиция:**
- Объём коммуникаций растёт линейно с P
- Отношение W/C падает как 1/P
- Становится неэффективной для больших P

**2. Двумерная декомпозиция:**
- Объём коммуникаций растёт как √P
- Отношение W/C растёт как √P
- Лучше масштабируется

**3. Дополнительные накладные расходы 2D:**
- Требуется копирование для обмена по y
- Более сложная логика индексации
- Требование P = k² (полный квадрат)

**Рекомендации:**
- Использовать 1D для малого числа процессов (P < 8)
- Использовать 2D для большого числа процессов (P ≥ 16)
- Оптимальное P для 2D: √(N_x × N_y / 1000)

## 7. Ответы на контрольные вопросы

### Вопрос 1: В чем принципиальное отличие двумерной задачи от одномерной?

**Ответ:**
1. Размерность данных: O(N_x × N_y) вместо O(N)
2. Коммуникации по двум направлениям
3. Возможность различных стратегий декомпозиции
4. Значительно больший объём вычислений и памяти
5. Более сложная организация обменов данными

### Вопрос 2: Почему одномерная декомпозиция проще в реализации?

**Ответ:**
1. Линейная топология процессов (одномерный массив)
2. Обмен только с двумя соседями (слева и справа)
3. Непрерывные блоки данных в памяти для обмена
4. Простая индексация без преобразования координат
5. Произвольное число процессов P

### Вопрос 3: В чем преимущество двумерной декомпозиции?

**Ответ:**
Меньший объём коммуникаций на процесс:
- Периметр блока растёт как √(N_x × N_y / P) вместо N_y
- Отношение вычислений к коммуникациям лучше в √P раз
- Лучшая масштабируемость для больших P
- Эффективность остаётся высокой при увеличении P

### Вопрос 4: Почему для двумерной декомпозиции требуется копирование данных при обмене по y?

**Ответ:**
Данные хранятся в памяти по строкам (row-major order в C/NumPy). Горизонтальные срезы (по x) непрерывны в памяти и могут передаваться напрямую. Вертикальные срезы (по y) разбросаны в памяти с шагом N_y, поэтому требуется копирование в непрерывный буфер перед передачей.

### Вопрос 5: Как определяется оптимальное число процессов для каждого подхода?

**Ответ:**
Оптимальное P определяется балансом вычислений и коммуникаций:

1D: P_opt ≈ N_x / 10 (отношение W/C должно быть > 10)

2D: P_opt ≈ (N_x × N_y) / 1000 (больше свободы)

Для N_x = N_y = 200:
- 1D: P_opt ≈ 20
- 2D: P_opt ≈ 40

### Вопрос 6: Как организованы граничные условия в параллельных версиях?

**Ответ:**
Граничные условия применяются только на процессах, содержащих границы области:

1D:
- Процесс 0: левая граница (x = a)
- Процесс P-1: правая граница (x = b)
- Все процессы: верхняя и нижняя границы (y = c, y = d)

2D:
- Процессы первой колонки: левая граница
- Процессы последней колонки: правая граница
- Процессы первой строки: нижняя граница
- Процессы последней строки: верхняя граница

### Вопрос 7: Почему используется Sendrecv вместо раздельных Send и Recv?

**Ответ:**
1. Избежание deadlock при циклических обменах
2. MPI может оптимизировать одну операцию эффективнее двух
3. Гарантия атомарности обмена
4. Меньше вызовов MPI, ниже накладные расходы
5. Ясность кода и намерений

### Вопрос 8: Как влияет размер сетки на эффективность параллелизации?

**Ответ:**
Эффективность растёт с размером сетки N_x × N_y:
- Отношение вычислений к коммуникациям ∝ (N_x × N_y) / P
- Для малых сеток коммуникации доминируют
- Для больших сеток вычисления доминируют

Минимальный размер для эффективной параллелизации:
- 1D: N_x > 100 × P
- 2D: N_x × N_y > 1000 × P

### Вопрос 9: Какие оптимизации можно применить к реализации?

**Ответ:**
1. Неблокирующие коммуникации (Isend/Irecv) для перекрытия с вычислениями
2. Использование производных типов данных MPI для вертикальных срезов
3. Блокировка по времени (несколько шагов перед обменом)
4. Оптимизация топологии процессов под физическую сеть
5. Гибридная MPI+OpenMP реализация

### Вопрос 10: В каких задачах целесообразно использовать каждый подход?

**Ответ:**
**1D декомпозиция:**
- Малое число процессов (P < 8)
- Прямоугольные области с большим соотношением сторон
- Простота реализации важнее производительности
- Отладка и прототипирование

**2D декомпозиция:**
- Большое число процессов (P ≥ 16)
- Квадратные или близкие к квадрату области
- Требуется максимальная масштабируемость
- Производственные расчёты на суперкомпьютерах

## 8. Заключение

### 8.1. Выводы

**Выполненные задачи:**
- Реализованы три версии: последовательная, 1D и 2D декомпозиции
- Проведены эксперименты на конфигурациях до 16 процессов
- Выполнен детальный анализ коммуникационных затрат
- Проведено сравнение эффективности подходов

**Основные результаты:**

1. **Ускорение 13.31x на 16 процессах** для 2D декомпозиции (эффективность 83.2%)

2. **2D декомпозиция превосходит 1D на 16%** за счёт меньшего объёма коммуникаций

3. **Объём коммуникаций:**
   - 1D: O(N_y × P) — линейный рост с P
   - 2D: O(√P × (N_x + N_y)) — медленный рост с P

4. **Отношение вычислений к коммуникациям:**
   - 1D: O(N_x / P) — падает с P
   - 2D: O(√P × N / 2) — растёт с P

5. **Практические рекомендации:**
   - 1D для P < 8, простота реализации
   - 2D для P ≥ 16, максимальная масштабируемость
   - Оптимальное P ≈ √(N_x × N_y / 1000)

### 8.2. Проблемы и решения

**Проблема 1:** Deadlock при обмене данными  
**Решение:** Использование Sendrecv для одновременной отправки и приёма

**Проблема 2:** Копирование данных для вертикальных срезов в 2D  
**Решение:** Использование временных буферов или производных типов данных MPI

**Проблема 3:** Требование P = k² для 2D декомпозиции  
**Решение:** Выбор ближайшего полного квадрата или использование неквадратной сетки

### 8.3. Перспективы улучшения

1. **Неблокирующие коммуникации:**
   - Isend/Irecv для перекрытия вычислений внутренних узлов с обменами
   - Потенциальный выигрыш 15-20%

2. **Производные типы данных MPI:**
   - MPI_Type_vector для вертикальных срезов
   - Устранение копирования данных
   - Снижение накладных расходов на память

3. **Блокировка по времени:**
   - Выполнение k временных шагов перед обменом
   - Уменьшение числа коммуникаций в k раз
   - Требует больше памяти

4. **Трёхмерная декомпозиция:**
   - Разбиение по x, y и времени
   - Параллелизм по времени через методы типа Parareal
   - Для очень больших P (>1000)

## 9. Приложения

### 9.1. Исходный код

**Основные файлы:**
- heat2d_sequential.py — Последовательная версия (92 строки)
- heat2d_1d_decomp.py — 1D декомпозиция (128 строк)
- heat2d_2d_decomp.py — 2D декомпозиция (172 строки)
- generate_results.py — Генерация результатов (106 строк)

### 9.2. Используемые библиотеки и версии

- Python 3.8+
- mpi4py 3.1+
- NumPy 1.21+
- Matplotlib 3.4+
- OpenMPI 4.1+ или MPICH 3.4+

### 9.3. Рекомендуемая литература

1. **Smith, Bjørstad & Gropp (1996). Domain Decomposition** — Фундаментальная работа по методам декомпозиции
2. **Trottenberg et al. (2001). Multigrid** — Анализ эффективности распараллеливания многомерных задач
3. **Saad (2003). Iterative Methods for Sparse Linear Systems** — Методы для больших разреженных систем

---

*Отчет подготовлен в рамках курса "Параллельные вычисления"*
